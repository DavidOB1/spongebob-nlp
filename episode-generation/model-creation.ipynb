{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-creation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "szEszybsa4jW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this model is to be able to generate a synopsis for a SpongeBob episode based on a given title. I have collected data from the [SpongeBob wiki](https://spongebob.fandom.com/wiki/Encyclopedia_SpongeBobia) and paired episode titles with their given sumamries. Hopefully, this data can help fine-tune a model to be able to output SpongeBob episodes similar in style to how the sumarries are written on the SpongeBob wiki."
      ],
      "metadata": {
        "id": "SUGNuPN4a8AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Creation**"
      ],
      "metadata": {
        "id": "HODCfoLKZ6w9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparations"
      ],
      "metadata": {
        "id": "BKvS84rMaLhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before I can fine-tune the model, I have to first install the needed packages and ensure the data is ready for GPT3 to use. I will be using an OpenAI tool that makes suggestions on how to optomize my data for model use and will be implementing the suggestions in order to hopefully optomize the model's performance.\n",
        "\n",
        "Additionally, I needed to set the OpenAI API key. The code of me doing this has been excluded, but if you wish to run this code yourself, make sure you set the OpenAI API key environment variable to your own API key."
      ],
      "metadata": {
        "id": "DPZj2KqCafjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfkBqq_smkGh",
        "outputId": "a0d5a4dd-3468-4f97-ff6a-17201c20e859"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.20.0.tar.gz (42 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42 kB 750 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.6.15)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.20.0-py3-none-any.whl size=54118 sha256=9548c62ed9824690df4fd3f8bfe56b8eaf4e8f5fef65c0c394ead8245ca162c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/8d/9b/e28529ec53123e0279208f99148d4661232120d78cb866839b\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.20.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f spongebob-data.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCwoKAXmpvM",
        "outputId": "4c62fbfe-c7b2-42fc-f2f1-e497c00abcdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging requires wandb to be installed. Run `pip install wandb`.\n",
            "Analyzing...\n",
            "\n",
            "- Your file contains 509 prompt-completion pairs\n",
            "- There are 2 examples that are very long. These are rows: [191, 334]\n",
            "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 2 long examples [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `***` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `spongebob-data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"spongebob-data_prepared.jsonl\"\n",
            "\n",
            "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"***\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 26.98 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning"
      ],
      "metadata": {
        "id": "1pGz2b2ScImS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I will be creating a fine-tuned model based off the aforementioned data, then I will run a test input in order to analyze whether the model works as intended."
      ],
      "metadata": {
        "id": "I-HTUufadGG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t \"file-1rdrvuvGQMc5RsgaarrA19PA\" -m \"curie\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOUvSgCR27vR",
        "outputId": "4752f409-64b4-41b3-d63b-2fb7df4af55b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging requires wandb to be installed. Run `pip install wandb`.\n",
            "Created fine-tune: ft-I32aL3nFEdZFzST4ZVniXmSm\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-07-18 01:11:50] Created fine-tune: ft-I32aL3nFEdZFzST4ZVniXmSm\n",
            "[2022-07-18 01:11:54] Fine-tune costs $4.19\n",
            "[2022-07-18 01:11:55] Fine-tune enqueued. Queue number: 0\n",
            "[2022-07-18 01:11:57] Fine-tune started\n",
            "[2022-07-18 01:15:12] Completed epoch 1/4\n",
            "[2022-07-18 01:17:32] Completed epoch 2/4\n",
            "[2022-07-18 01:19:52] Completed epoch 3/4\n",
            "[2022-07-18 01:22:12] Completed epoch 4/4\n",
            "[2022-07-18 01:22:33] Uploaded model: curie:ft-personal-2022-07-18-01-22-33\n",
            "[2022-07-18 01:22:35] Uploaded result file: file-fMW4AVlcvSBvhxoK7ClwOmow\n",
            "[2022-07-18 01:22:35] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded ðŸŽ‰\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-personal-2022-07-18-01-22-33 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.Completion.create(\n",
        "    model=\"curie:ft-personal-2022-07-18-01-22-33\",\n",
        "    prompt=\"Plankton Steals the Formula\",\n",
        "    max_tokens=1500,\n",
        "    temperature=0.9,\n",
        "    frequency_penalty=0.75,\n",
        "    n=1\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELOavyZ_6XpP",
        "outputId": "398fd41a-ab22-4e22-8b93-05dd0a0f9fe0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject text_completion id=cmpl-5VBnLmEeKQbAkE5ii5tlrDmHp6Nya at 0x7fd529ff6bf0> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"logprobs\": null,\n",
              "      \"text\": \" -> Despite being on the run from the police and SpongeBob, the Chum Bucket thief Plankton manages to steal both the formula and the S.S. Krabby Patty secret formula, but his attempt fails when he trips over a piece of equipment. He ends up falling off of a bridge and lands back in his own kitchen, with Patrick. Plankton then realizes that this is his daughter Karen's (actual) birthday and gets an idea, leading to him leaving in his submarine with Karen as hostage along with both formulas.\\nLater at the Krusty Krab, Mr. Krabs is happy he got back the old formula when Plankton returns to give him SpongeBob while holding Karen along with the two formulas until they escape via freeze ray attack thanks to sending Plankton flying into a refrigerator twice before pushing it away using a fork as demonstrated by an image by Patrick\\nThen at night two thugs sneak into Mr. Krabs' office to arrest him for all debts along with Squidward for sure before stealing all customers' money except for Squidward's as well before leaving when they hear SpongeBob's voice outside wishing Mr. Krabs a happy birthday after he thought it was actually SpongeBob considering what happened earlier until they hear SpongeBob saying his name four times as punishment while bringing out some confetti onto their heads courtesy of breaking underwater glass bottles albeit shortly followed by Squidward saying \\\"Please don't hurt us!\\\" right after them once a pie hits Squidward right after that as part of Mr Bob Loblaw's plan only to escalate matters since getting revenge against them but even so right when they are about take down Mr Krabs himself where despite having strong arms, he tells them he figured out it was them since someone called their order without needing further explanation regarding their orders instead they believe they met accidentally in Neptunia Bikini Bottom which is where Neptune and Mobius resided according to him three years ago despite stating that according to themselves there has never been any such place before unlike how many times had there actually appeared The episode ends with Mr Krabs giving pies free to all Krusty Krew members except for Squidward like how he treats their respective members\\u2019 orders because according-to-him-it is not enough punishment enough due following next week's episode preview And now another normal week on Bikini Bottom Radio starting now Where those who try do remember....A regular customer walks over thus revealing himself or herself after pushing through the door wanting some franchise shake at apparently 10:07 PM several minutes later A year ago today Nobody receives one random customer randomly walking into The Krusty Krab seemingly out of nowhere unless you count Principal Maligna Mott Live action Most likely VHS tape This person declares \\\"I'm gonna get me some shake\\\" while clapping his hands Double takes immediately realizing this customer is unfamiliar somehow Everyone else inside stares upon this person wearing weird clothing including shades covered by sunglasses Everyone else decides throw this guy out since seeing regular customers come around randomly like freaking ghosts All except Number One Random Customer Random Customer makes fun saying \\\"I'm ready\\\" then laughing Thrilled Elementary School Girl (TFSGS) runs over excitedly exclaims \\\"My favorite movie just came on TV!\\\" almost talking about Back To The Future Part II Back To The Future Part II Random Customer asks everybody if any one wants shake Random Teenage Girl TFSGS screams \\\"YES!\\\" saying her favorite movie just came video was shown repeatedly today She believes she just saw herself in Back To The Future Part 2 Video Everyone thinks she did something crazy TFSGS replies telling her not messed up randomly shouting about movies being real even mentioning meeting people from movies too Random Teenager Askee points off making fun of her which infuriates TFSGS massively Broken Nose Cracks Around He places himself forthrightly between random teenager asker putting his arms behind back like people during times of war Evil Bank Robber (EBR) announces theft announcing bank robbing everyone stupid wanting money Blondes vs Red Heads Bald Dude says red head hire bald dude but blondes don't work tacos holds taco eating mustard sauce Hired Mexican eats taco lifting mustache Off Screen Man #2 calmly says \\\"You know my pace\\\" Three Men One Vacuum cleaner man sitting down yawning eating bread pretending middle aged unenthusiastic woman has white hair saying reread adress? Turtle Soup Lady screams sick party indeed hearing about monday morning fish fry Unless said Monday Morning Fish Fry Ought Be No Such Thing Wide Nostrils Aiken Peckham sporting bicuspid teeth Strange Face Distorted Face Guy stands insanely proud randomly shouting answers wrong Weirdos dancing around excitedly yells Cross Eyed Men Dance below stairs jumping off railing onto floor Unknown Stabbing Man sits stoically eating pineapple which scars someone who loves krabby patty Steve Johnson plays clarinet Fine Dining Boater guys talk about food boo good in boating house according Dai Architect Interupts Boater Guys interupting Billy Boat asking engineer something involving steve jenison playing guitar barefoot hiding under table playing cross Country Boy Hat Boy Gunman Middle Age Coot grabs skirt pulls aside revealing black female panty hose pants pirate shirt burglar suit guns down yellow lazer gun light blue helmet Jump Out Of Window Guy jumps high above window jumps plunging head first landing horribly injuring other person Dark Satanic Devil Man ordering cianfrocian broth lunches Many Nurse Nurse screams going insane seeing big toe big toe Doctor Doctor violently hitches up pants yelling disturbing noises Takes Off Cloth Of Light Or Sound Hearing Noises causing Crazy Woman Goes Insane screeching doctor repeatedly hitting desk Drawers Crazy Woman Asks Drastically Screaming Removing Bandages Nurse Angry On Soap Bubble Bubble shouts loudly demanding soap bubble soap bubble madam stuts ice dispenser punks bandaid snot bubbles farts Robert Berkland requests chowder soup At 10:34 PM A Nerd (NNR) riding Big Boat Racing Bike Speaking Engrish Allen Dullin throws rope rope rope rope ties tying mister boat boat boat i am parked over patient parking bus bus bus obviously diving Into Bus Van goes Forward America USA USA Carter performing emergency surgery Burger Barker roughly shouts beginning shout ordered garlic fries mozzarella cheese hamburger hamburgers simply speaking oranges onion rings pineapple Jim O'Hair potatoes potato poppers popping shots shooting Squirtle Mites watching children squeaking meat meat meat meat sounds fanning sprinkles sugars flashing sugar magnolia dates directed toward tree end dated scallops whole dill pickles holding cucumbers funny cucumber peas cartoon fruit cartoon series cartoon characters television animation cartoon network network network network skateboard Mustard full mouth four chins perposes little kid scream ketchup mustard Mustard Sauce Tower mustard sauce tower reading comic book comic book such comics reading silverware silverware written old ransom note shark eye ball bowl saltado boom boom shouting oh perfect title chop chop chop chop homer parkin noodle cooks noodles noodles soup soy sauce dishes sake spicy soysauce edamame edammon lentil sprouts Sprout Sprouts Sprouts Sprouts Sprouts Sprouts delicious words because add soybean sprout bean beans bean foods sprouting cherries red eyes devo coital dance dollar seed seeds seeds seeds be caring people care women more woman doing dance moves sonar sonar soups taxes taxes taxes taxes taxes film financial future financial future years distant future dollars dollars dollars dollars millions millions millions miles miles mile mile mile miles year years new ham\"\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1658115191,\n",
              "  \"id\": \"cmpl-5VBnLmEeKQbAkE5ii5tlrDmHp6Nya\",\n",
              "  \"model\": \"curie:ft-personal-2022-07-18-01-22-33\",\n",
              "  \"object\": \"text_completion\",\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 1500,\n",
              "    \"prompt_tokens\": 7,\n",
              "    \"total_tokens\": 1507\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is very much evident, this is not a very coherent episode at all. While the output starts off readable (although lacking a lot of consistency), the output slowly devolves into more confusing nonsense. Part of this has to do with the limited ability of GPT3 to create large outputs for text completion. While I was optomistic that fine-tuning on large episode summaries could potnetially help to overcome this, it is evident that this is definetly not the case.\n",
        "\n",
        "Therefore, my next plan is to make the max token size a much smaller number in order to make the output more coherent. However, to complete the episode, I will continually pass the output as input to the Davinci model, where it will progressivly build more and more of the episode, until it either reaches its token limit or runs out of things to add. Essentially, this is like using the fine-tuned model to get ball rolling on what to create the SpongeBob episode around, then using pre-existing models to finish up the job."
      ],
      "metadata": {
        "id": "yviFuRS5d2Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a SpongeBob episode based off of the given title\n",
        "def gen_ep(title):\n",
        "  # Gets an initial output from the fine-tuned model\n",
        "  ft_model_res = gen_new_output(title, \"curie:ft-personal-2022-07-18-01-22-33\", 250)\n",
        "  res_text = ft_model_res[\"choices\"][0][\"text\"][4:]\n",
        "\n",
        "  # Initializes the necessary variables for the next step\n",
        "  res_tokens = ft_model_res[\"usage\"][\"total_tokens\"]\n",
        "  prev_tokens = 0\n",
        "  res_output = f\"\\\"{title}\\\"\\n{res_text}\"\n",
        "\n",
        "  # Continually makes calls to the Davinci model to add more to the episode until\n",
        "  # either the max length is reached or the model ends the episode and cannot add more\n",
        "  while res_tokens < 1750 and res_tokens - prev_tokens > 5:\n",
        "    # Makes a new call to the model\n",
        "    res = gen_new_output(res_output, \"text-davinci-001\", min(2000 - res_tokens, 350))\n",
        "\n",
        "    # Updates the ongoing text and token variables\n",
        "    res_output += res[\"choices\"][0][\"text\"]\n",
        "    prev_tokens = res_tokens\n",
        "    res_tokens = res[\"usage\"][\"total_tokens\"]\n",
        "\n",
        "  # Returns the text of the episode\n",
        "  return res_output\n",
        "\n",
        "\n",
        "# When given an input, model name, and max tokens, returns the output from that model\n",
        "def gen_new_output(input, model, tokens):\n",
        "  return openai.Completion.create(\n",
        "    model=model,\n",
        "    prompt=input,\n",
        "    max_tokens=tokens,\n",
        "    temperature=0.9,\n",
        "    frequency_penalty=0.75,\n",
        "    n=1\n",
        "  )"
      ],
      "metadata": {
        "id": "3ToeszQ870BH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examples"
      ],
      "metadata": {
        "id": "p1devGRVgY8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with character name in the title\n",
        "print(gen_ep(\"Krabs Goes Broke\"))\n",
        "print(\"===============================\")\n",
        "# Example with common item on the show in the title\n",
        "print(gen_ep(\"The Chum Monster\"))\n",
        "print(\"===============================\")\n",
        "# Example with nothing related to the show in the title\n",
        "print(gen_ep(\"The New Zoo\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3tTzaROgb4-",
        "outputId": "9b1c8a9c-594b-478a-ef44-cf3bf8f120ca"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Krabs Goes Broke\"\n",
            "In the beginning of the episode, SpongeBob arrives at Mr. Krabs' Velma Cammobile to start his day at work. While helping Mr. Krabs open his safe with a crowbar, the crab tells SpongeBob that he needs to make sure no one borrows money from him during the next 24 hours. However, due to having spent most of his own funds on various things (including a kickback from Squidward's book rental), he can barely afford any food for himself for lunch.\n",
            "It then shows Patrick buying all kinds of things at his convenience store without paying for them, such as 32 bags of sugar, a never-ending supply of coffee creamer and a bag of seaweed snacks without buying any actual food items. When Squidward objects and suggests that Patrick buys some hot dogs instead, the latter states he only has fifty cents and reveals that SpongeBob knows how to get that amount in less than twenty seconds in exchange for not telling anyone about this \"secret.\"\n",
            "Squidward suggests they go into business with each other until SpongeBob pays him back (however this will never happen), but Patrick just laughs at this before going back home with Gary. Trying to hide what he did from Mr. Krabs, SpongeBob goes to work, but the crab soon finds out and fires him.\n",
            "\n",
            "After Squidward quits his job in protest, Mr. Krabs is left with no employees to run his business. This eventually leads to him being forced to sell the restaurant to a group of anchovies for $100 due to having no other choice (aside from declaring bankruptcy). \n",
            "The anchovies apparently do not know how to cook Krabby Patties, as they are revealed to be serving them frozen and burnt. This eventually leads to the customers revolting and chasing Mr. Krabs out of his own restaurant. \n",
            "Ending back at his office, an exhausted Mr. Krabs falls asleep on his desk with a tear running down his eye.\n",
            "\n",
            "Later, Plankton is seen celebrating his victory as he now owns the Krusty Krab (due to buying it for a very low price) and has turned it into a mobile Chum Bucket food truck, much to the horror of the citizens of Bikini Bottom.\n",
            "\n",
            "Patrick arrives outside Mr. Krabs' office window (using a fishing rod as a makeshift crane) with a bag of money and tells him that he managed to get it from SpongeBob in exchange for not telling anyone about their secret agreement (although he does not remember what it was). This finally allows Mr. Krabs to buy back the Krusty Krab from Plankton and re-open it as if nothing ever happened...although Gary is now working for Plankton as part of their deal (which Plankton does not know about).\n",
            "\n",
            "Some time later, it is shown that due to Mr. Krabs being more careful with his money, the Krusty Krab is now more successful than ever before (with Squidward back as his cashier). Patrick then comes in, asking for a Krabby Patty but is informed by Squidward that they cost $7.99 now. SpongeBob arrives soon afterwards with a bag of money, revealing that he has been working for Mr. Krabs as a part-time security guard to help him out and make some extra money. \n",
            "\n",
            "This episode implies that Mr. Krabs went bankrupt and lost the Krusty Krab, but was able to buy it back from Plankton and re-open it.\n",
            "===============================\n",
            "\"The Chum Monster\"\n",
            "As the episode begins, Squidward is watching television, until he hears a commercial for Reality Bites magazine about the newest monster known as The Chum Monster, which is terrorizing the Bikini Bottom fishing community. Due to his love of fish horror, Squidward assumes that it must be fun to be killed by a giant, rotten fish head monster and decides to go out on a quest to slay the beast. After constructing several cardboard boomerangs from his paper towel roll, he goes out into the streets and finds that Sandy has already warned everyone about The Chum Monster. He finds Patrick raking leaves and convinces him to come with him on his adventure. However, Patrick only wants to know how many blades are in Squidward's box \"clip-clopping toward me.\" He then tells Patrick that he will tell him when they reach it and leaves while two fishing boats begin playing Annoying Annoying Song simultaneously once they are not paying attention.\n",
            "He then goes into SpongeBob's pineapple house and tries to convince SpongeBob join on his quest but fails when Mrs. Puff interrupts them claiming she works out with weights while listening to a sound system until they accidentally destroy her house grabbing weights while trying to lift up her couch. Squidward leaves as Mrs. Puff tries to think of a way to get SpongeBob in trouble. \n",
            "Squidward and Patrick reach the spot where the fishing boats are playing the Annoying Song and find that they are getting closer to the Chum Monster. Squidward tries to throw a boomerang at it, but it just comes back and hits him in the face. The Chum Monster starts chasing them, and they run away until they run into a dead end. The Chum Monster catches up to them and starts eating them, but they are saved by Sandy who shows up riding on top of a giant clam.\n",
            "===============================\n",
            "\"The New Zoo\"\n",
            "At the Krusty Krab one day, SpongeBob makes a new fish order, but when he sees that it's just a seal, he calls his coworkers to come and see. Squidward berates him for letting another customer go to the facility \"the way it is\" and makes it clear that he will be taking over SpongeBob's duties. This causes SpongeBob to argue with Squidward and run away crying.\n",
            "SpongeBob goes out at night and cries next to a sea urchin test dig site, where he expresses his worry over what Squidward will do with the restaurant until Patrick says that everything will be fine in the morning. Afterwards, they decide to put on a show for Squidward as an apology for hurting his feelings while warning him of what they plan on doing (such as pulling knobs from their eyes and farting loudly) before assaulting him when he arrives at work the next morning.\n",
            "Squidward panics as he tries to get things organized and asks Sandy for help, who reminds him of his condition \"temporary subaquianetarian.\" She takes this statement literally and leaves causing him to do so as well. With no-one around but SpongeBob (who tried panicking Squidward on purpose), Squidward starts to feel better and learns that he was too hard on SpongeBob. He tries to get the Krusty Krab back to its former state, but things only get worse. \n",
            "In the end, SpongeBob and Patrick present a show to Squidward (of them cleaning the Krusty Krab), which makes him happy and allows him to take a break.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "nGS_4Hn1lVKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimately, it's obvious that the second strategy of using smaller token sizes on each model call worked signficantly better than my original plan of generating an entire episode synopsis just from one use of the model. However, this is not to say that the results are flawless. The above examples show that, while the episode summaries generally read coherently, there are still many major issues in the plots that are developed that can leave you scratching your head on what is going on, as well as there being many awkwardly structured sentences that can be misunderstood at first. However, amidst all these issues, the generated episodes did show a good amount of creativity and interesting story telling at some parts.\n",
        "\n",
        "What is definetely noticeable from the above examples is that the specificty of the title helps a lot in keeping it alligned with the topic. The first example of \"Krabs Goes Broke\" generated an episode that very much focuses on this idea, whereas the last example of \"The New Zoo\" has practically very little with a zoo. Perhaps re-tuning the model to take a brief sentence summary of an episode rather than the title could lead to much better results.\n",
        "\n",
        "Overall, the idea of using a model to generate a cartoon episode could have implications in other uses of AI. For example, rather than generating SpongeBob episodes, one could perhaps fine-tune a model to give suggestions on what improvements a company should make to its product or what new and interesting coding projects one could pursue. While the output of my model wasn't perfect, it illustrates GTP3's ability to be creative and think of new ideas."
      ],
      "metadata": {
        "id": "hya_n0PvlW4C"
      }
    }
  ]
}